{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpconda58a66029c51549b7b2d39520295f4ea7",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preparaci√≥n del Dataset\n",
    "---\n",
    "\n",
    "- Se obtienen y preprocesan textos directos del dataset para luego ser persistidos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from document import Document\n",
    "import util.log as log\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "log.init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = []\n",
    "init_time = datetime.now()\n",
    "directory = '../labeled_dataset/'\n",
    "files = os.listdir(directory)\n",
    "dataframe = None\n",
    "number_of_cores_to_use = 10\n",
    "\n",
    "def process_file(file):\n",
    "    log.info('Processing file: {}'.format(file))\n",
    "    try:\n",
    "        path = '{}{}'.format(directory, file)\n",
    "        document = Document(path = path)\n",
    "        splitted_file = file.split(' $ ') \n",
    "        topic = splitted_file[0]\n",
    "        title = splitted_file[1]\n",
    "        return [path, title, document.string, document.word_count(), document.type_count(), document.sentences,\\\n",
    "                       document.lemmatized_string, document.stemmed_string, document.simple_preprocessed_string, topic, \\\n",
    "                       document.named_entities, document.bigrams, document.trigrams, document.lemmatized_bigrams, \\\n",
    "                       document.lemmatized_trigrams, document.stemmed_bigrams, document.stemmed_trigrams, \\\n",
    "                       document.simple_preprocessed_bigrams, document.simple_preprocessed_trigrams]\n",
    "    except InvalidDocument:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "with Pool(number_of_cores_to_use) as pool:\n",
    "    corpora = pool.map(process_file, files)\n",
    "\n",
    "time = datetime.now() - init_time\n",
    "log.info('{} documents were processed. {} documents errored. Total time used: {}, Total cores used: {}'.format(len(corpora), corpora.count([]), \\\n",
    "                                                                                                          str(time), number_of_cores_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data = corpora, columns=['original_path', 'document_title', 'string', 'word_count', 'type_count', 'sentences','lemmatized_text', 'stemmed_text', 'simple_preprocessed', 'topic', 'named_entities', 'tokens_bigrams', 'tokens_trigrams', 'lemmatized_bigrams', 'lemmatized_trigrams', 'stemmed_bigrams', 'stemmed_trigrams', 'simple_preprocessed_bigrams', 'simple_preprocessed_trigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf31bbbaa179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "dir([].remove(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}