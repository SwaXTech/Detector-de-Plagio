{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpconda58a66029c51549b7b2d39520295f4ea7",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## Modelo de clasificación de textos de manera supervisada\n",
    "\n",
    "- [Documentación utilizada](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b#:~:text=The%20Naive%20Bayes%20classifier%20is,time%20and%20less%20training%20data)\n",
    "\n",
    "- [Referencia](https://www.campusvirtual.frba.utn.edu.ar/especialidad/pluginfile.php/300766/mod_resource/content/1/NLP%20-%20UTN%20-%20Clase%203.pdf)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Preparación del dataset\n",
    "\n",
    "- Obtención del dataset de un `CSV`\n",
    "- Ignoramos las columnas innecesarias\n",
    "- Limpieza de datos\n",
    "- Separación de dataset en Train/Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Teorema de Bayes\n",
    "\n",
    "![](https://miro.medium.com/max/358/1*8vBP06EtIIf-420o_q1u6g.png)\n",
    "\n",
    "\n",
    "Se debe calcular qué tópico tiene mayor probabilidad para una texto determinado\n",
    "\n",
    "¿`P(c1 | unTexto)` es mayor que `P(c2 | unTexto)`?\n",
    "\n",
    "Según el Teorema de Bayes, esto se puede calcular de la siguiente manera:\n",
    "\n",
    "`P(c | unTexto) = (P(unTexto | c) * P(c)) / P(unTexto)`\n",
    "\n",
    "Como para ambas clases el denominador es el mismo, podemos ignorarlo y nos queda:\n",
    "\n",
    "`P(c | unTexto) = P(unTexto | c) * P(c)`\n",
    "\n",
    "Finalmente\n",
    "\n",
    "`P(c) = count(textos, c) / count(textos, dataset)` \n",
    "\n",
    "`P(unTexto) = count(unTexto, c) / count(textos, c)`\n",
    "\n",
    "Dado que los textos a evaluar no necesariamente aparecen en el dataset, y por consiguiente su probabilidad es cero. Entonces se asumen todas las palabras independientes. Ésto se lo conoce como [Markov Assumption](https://es.wikipedia.org/wiki/Proceso_de_M%C3%A1rkov)\n",
    "\n",
    "Entonces teniendo en cuenta lo mencionado:\n",
    "\n",
    "`P(unTexto | c) = P(w1 | c) * P(w2 | c) * ... * P(wn | c)`\n",
    "\n",
    "Siendo\n",
    "\n",
    "`P(unaPalabra | c) = count(unaPalabra, c) / count(palabras, c)`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from repository.csv_tools import get_documents\n",
    "import random\n",
    "from util.count_vectorizer import MyCountVectorizer\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from models.naive_bayes_utils import *"
   ]
  },
  {
   "source": [
    "## Preparación del dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents('../data/dataset.csv')\n",
    "preprocessed_docs = [(document.lemmatized_string, document.topic) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, classes_train, text_test, classes_test = split_dataset(preprocessed_docs, 0.2)"
   ]
  },
  {
   "source": [
    "## Entrenamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = set(classes_train)\n",
    "frequencies = {}\n",
    "probabilities = {}\n",
    "features_by_class = {}\n",
    "\n",
    "def process(topic):\n",
    "    documents = get_documents_from_class(texts_train, classes_train, topic)\n",
    "\n",
    "    vectorizer           = MyCountVectorizer(preprocess = False)\n",
    "    term_document_matrix = vectorizer.fit_transform(documents)\n",
    "    word_list            = get_words(vectorizer)\n",
    "    count_list           = get_words_count(term_document_matrix)\n",
    "\n",
    "    __frequencies = get_frecuencies(word_list, count_list)\n",
    "    __probabilities = get_probabilities(word_list, count_list)\n",
    "    __features_by_class = get_features_count(count_list)\n",
    "   \n",
    "    return (__frequencies, __probabilities, __features_by_class, topic)\n",
    "    \n",
    "\n",
    "with Pool(10) as pool:\n",
    "    results = pool.map(process, classes)\n",
    "\n",
    "for result in results:\n",
    "    topic = result[3]\n",
    "    frequencies[topic] = result[0]\n",
    "    probabilities[topic] = result[1]\n",
    "    features_by_class[topic] = result[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total features: 4304\n"
     ]
    }
   ],
   "source": [
    "total_features = get_total_features(frequencies, classes)\n",
    "print('Total features: {}'.format(total_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class: La larga cola has a P = 0.15510204081632653\nClass: Economia de experiencia has a P = 0.22040816326530613\nClass: Adopcion y difusion has a P = 0.1836734693877551\nClass: Nueva economia has a P = 0.024489795918367346\nClass: Wikinomics has a P = 0.09795918367346938\nClass: La sociedad de costo marginal cero has a P = 0.12244897959183673\nClass: Sistemas emergentes has a P = 0.08979591836734693\nClass: El dominio de la informacion has a P = 0.00816326530612245\nClass: Marketing 4.0 has a P = 0.04897959183673469\nClass: E-commerce has a P = 0.024489795918367346\nClass: Machine - Platform - Crowd has a P = 0.012244897959183673\nClass: Realidad virtual has a P = 0.004081632653061225\nClass: Plataformas y modelos de negocio has a P = 0.004081632653061225\nClass: Domotica has a P = 0.004081632653061225\n"
     ]
    }
   ],
   "source": [
    "class_probabilities = get_class_probabilities(classes_train)\n",
    "\n",
    "for topic in class_probabilities.keys():\n",
    "    print('Class: {} has a P = {}'.format(topic, class_probabilities[topic]))"
   ]
  },
  {
   "source": [
    "## Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.naive_bayes_utils import NaiveBayes\n",
    "classifier = NaiveBayes()\n",
    "classifier.init(frequencies, classes, features_by_class, class_probabilities)\n",
    "classifier.save_model(path = '../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For document #0: Predicted topic: La larga cola with P = -1728.399955793279. Real topic: La larga cola\n",
      "For document #1: Predicted topic: La sociedad de costo marginal cero with P = -1699.7607884193883. Real topic: La sociedad de costo marginal cero\n",
      "For document #2: Predicted topic: La larga cola with P = -2267.2486363063326. Real topic: La larga cola\n",
      "For document #3: Predicted topic: El dominio de la informacion with P = -5697.110132994869. Real topic: El dominio de la informacion\n",
      "For document #4: Predicted topic: Machine - Platform - Crowd with P = -1707.8647781047532. Real topic: Machine - Platform - Crowd\n",
      "For document #5: Predicted topic: La larga cola with P = -2129.4351930576954. Real topic: La larga cola\n",
      "For document #6: Predicted topic: Sistemas emergentes with P = -1111.0794155079873. Real topic: Sistemas emergentes\n",
      "For document #7: Predicted topic: Sistemas emergentes with P = -1607.3719337785915. Real topic: Sistemas emergentes\n",
      "For document #8: Predicted topic: La sociedad de costo marginal cero with P = -1488.1244019694566. Real topic: La sociedad de costo marginal cero\n",
      "For document #9: Predicted topic: La larga cola with P = -2467.0310038659945. Real topic: La larga cola\n",
      "For document #10: Predicted topic: La larga cola with P = -1636.3419587955943. Real topic: La larga cola\n",
      "For document #11: Predicted topic: La sociedad de costo marginal cero with P = -1651.811624125056. Real topic: La sociedad de costo marginal cero\n",
      "For document #12: Predicted topic: Economia de experiencia with P = -1127.3073733763736. Real topic: Economia de experiencia\n",
      "For document #13: Predicted topic: E-commerce with P = -1543.4184960069338. Real topic: E-commerce\n",
      "For document #14: Predicted topic: Sistemas emergentes with P = -1344.3135831599898. Real topic: Sistemas emergentes\n",
      "For document #15: Predicted topic: Economia de experiencia with P = -1360.0977168269415. Real topic: Economia de experiencia\n",
      "For document #16: Predicted topic: E-commerce with P = -1328.9213257512802. Real topic: E-commerce\n",
      "For document #17: Predicted topic: La sociedad de costo marginal cero with P = -1801.9156103606833. Real topic: La sociedad de costo marginal cero\n",
      "For document #18: Predicted topic: La larga cola with P = -3130.193166519249. Real topic: La larga cola\n",
      "For document #19: Predicted topic: Sistemas emergentes with P = -972.1744862795815. Real topic: Sistemas emergentes\n",
      "For document #20: Predicted topic: La larga cola with P = -2761.94944382655. Real topic: La larga cola\n",
      "For document #21: Predicted topic: Wikinomics with P = -2762.124531078748. Real topic: Wikinomics\n",
      "For document #22: Predicted topic: La larga cola with P = -1857.4430329664121. Real topic: La larga cola\n",
      "For document #23: Predicted topic: La larga cola with P = -1187.8835257050034. Real topic: La larga cola\n",
      "For document #24: Predicted topic: Nueva economia with P = -1476.670108322555. Real topic: Nueva economia\n",
      "For document #25: Predicted topic: Machine - Platform - Crowd with P = -1094.061347043337. Real topic: Plataformas y modelos de negocio\n",
      "For document #26: Predicted topic: Economia de experiencia with P = -3223.8479129850975. Real topic: Economia de experiencia\n",
      "For document #27: Predicted topic: Sistemas emergentes with P = -1218.2434195286467. Real topic: Sistemas emergentes\n",
      "For document #28: Predicted topic: Adopcion y difusion with P = -1917.6195959376082. Real topic: Adopcion y difusion\n",
      "For document #29: Predicted topic: Marketing 4.0 with P = -3444.2478705603467. Real topic: Marketing 4.0\n",
      "For document #30: Predicted topic: Wikinomics with P = -1849.8545335710357. Real topic: Wikinomics\n",
      "For document #31: Predicted topic: Adopcion y difusion with P = -1454.4013994673164. Real topic: Adopcion y difusion\n",
      "For document #32: Predicted topic: La sociedad de costo marginal cero with P = -2419.4431731087025. Real topic: La sociedad de costo marginal cero\n",
      "For document #33: Predicted topic: E-commerce with P = -1461.3782567686221. Real topic: E-commerce\n",
      "For document #34: Predicted topic: E-commerce with P = -1847.947017939992. Real topic: E-commerce\n",
      "For document #35: Predicted topic: Sistemas emergentes with P = -1486.3167194395148. Real topic: Sistemas emergentes\n",
      "For document #36: Predicted topic: Adopcion y difusion with P = -2451.297173104215. Real topic: Adopcion y difusion\n",
      "For document #37: Predicted topic: Sistemas emergentes with P = -972.1744862795815. Real topic: Sistemas emergentes\n",
      "For document #38: Predicted topic: Wikinomics with P = -2386.173080657578. Real topic: Wikinomics\n",
      "For document #39: Predicted topic: La larga cola with P = -2272.048130856367. Real topic: La larga cola\n",
      "For document #40: Predicted topic: Marketing 4.0 with P = -5159.522962264913. Real topic: Marketing 4.0\n",
      "For document #41: Predicted topic: Economia de experiencia with P = -2001.6114024043552. Real topic: Economia de experiencia\n",
      "For document #42: Predicted topic: La larga cola with P = -2437.1030750139325. Real topic: La larga cola\n",
      "For document #43: Predicted topic: La sociedad de costo marginal cero with P = -3996.3838138384776. Real topic: La sociedad de costo marginal cero\n",
      "For document #44: Predicted topic: El dominio de la informacion with P = -894.4221736453393. Real topic: Python\n",
      "For document #45: Predicted topic: Adopcion y difusion with P = -1528.4104545128566. Real topic: Adopcion y difusion\n",
      "For document #46: Predicted topic: Wikinomics with P = -2951.5255843369005. Real topic: Wikinomics\n",
      "For document #47: Predicted topic: Adopcion y difusion with P = -2451.297173104215. Real topic: Adopcion y difusion\n",
      "For document #48: Predicted topic: Economia de experiencia with P = -2359.2830704389107. Real topic: Economia de experiencia\n",
      "For document #49: Predicted topic: La larga cola with P = -3300.0048769060527. Real topic: La larga cola\n",
      "For document #50: Predicted topic: Economia de experiencia with P = -1554.2701738818487. Real topic: Economia de experiencia\n",
      "For document #51: Predicted topic: Machine - Platform - Crowd with P = -1640.755377026698. Real topic: Plataformas y modelos de negocio\n",
      "For document #52: Predicted topic: Sistemas emergentes with P = -1198.3098149588884. Real topic: Sistemas emergentes\n",
      "For document #53: Predicted topic: Marketing 4.0 with P = -3081.943964785063. Real topic: Marketing 4.0\n",
      "For document #54: Predicted topic: Sistemas emergentes with P = -1266.9855113963436. Real topic: Sistemas emergentes\n",
      "For document #55: Predicted topic: Adopcion y difusion with P = -1825.957908388955. Real topic: Adopcion y difusion\n",
      "For document #56: Predicted topic: Economia de experiencia with P = -2301.1728989907506. Real topic: Economia de experiencia\n",
      "For document #57: Predicted topic: La larga cola with P = -1172.1045326143787. Real topic: La larga cola\n",
      "For document #58: Predicted topic: Sistemas emergentes with P = -1955.4986816179273. Real topic: Sistemas emergentes\n",
      "For document #59: Predicted topic: Adopcion y difusion with P = -1862.7954849897837. Real topic: Adopcion y difusion\n",
      "For document #60: Predicted topic: Economia de experiencia with P = -2100.095128428703. Real topic: Economia de experiencia\n"
     ]
    }
   ],
   "source": [
    "successfuly = 0\n",
    "failed = 0 \n",
    "total = len(text_test)\n",
    "\n",
    "for ix, document in enumerate(text_test[:]):\n",
    "    topic_predicted, probability_predicted = classifier.topic(document)\n",
    "    if topic_predicted == classes_test[ix]:\n",
    "        successfuly += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "    print('For document #{}: Predicted topic: {} with P = {}. Real topic: {}'.format(ix, topic_predicted, probability_predicted, classes_test[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "El modelo acertó el 95.08196721311475% de las veces\nEl modelo falló el 4.918032786885246% de las veces\n"
     ]
    }
   ],
   "source": [
    "fiability = {\n",
    "\n",
    "    'accuracy': (successfuly*100)/total,\n",
    "    'failed': (failed*100)/total\n",
    "}\n",
    "\n",
    "print('El modelo acertó el {}% de las veces'.format(fiability['accuracy']))\n",
    "print('El modelo falló el {}% de las veces'.format(fiability['failed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}