{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpconda58a66029c51549b7b2d39520295f4ea7",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## Modelo de clasificación de textos de manera supervisada\n",
    "\n",
    "- [Documentación utilizada](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b#:~:text=The%20Naive%20Bayes%20classifier%20is,time%20and%20less%20training%20data)\n",
    "\n",
    "- [Referencia](https://www.campusvirtual.frba.utn.edu.ar/especialidad/pluginfile.php/300766/mod_resource/content/1/NLP%20-%20UTN%20-%20Clase%203.pdf)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Preparación del dataset\n",
    "\n",
    "- Obtención del dataset de un `CSV`\n",
    "- Ignoramos las columnas innecesarias\n",
    "- Limpieza de datos\n",
    "- Separación de dataset en Train/Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Teorema de Bayes\n",
    "\n",
    "![](https://miro.medium.com/max/358/1*8vBP06EtIIf-420o_q1u6g.png)\n",
    "\n",
    "\n",
    "Se debe calcular qué tópico tiene mayor probabilidad para una texto determinado\n",
    "\n",
    "¿`P(c1 | unTexto)` es mayor que `P(c2 | unTexto)`?\n",
    "\n",
    "Según el Teorema de Bayes, esto se puede calcular de la siguiente manera:\n",
    "\n",
    "`P(c | unTexto) = (P(unTexto | c) * P(c)) / P(unTexto)`\n",
    "\n",
    "Como para ambas clases el denominador es el mismo, podemos ignorarlo y nos queda:\n",
    "\n",
    "`P(c | unTexto) = P(unTexto | c) * P(c)`\n",
    "\n",
    "Finalmente\n",
    "\n",
    "`P(c) = count(textos, c) / count(textos, dataset)` \n",
    "\n",
    "`P(unTexto) = count(unTexto, c) / count(textos, c)`\n",
    "\n",
    "Dado que los textos a evaluar no necesariamente aparecen en el dataset, y por consiguiente su probabilidad es cero. Entonces se asumen todas las palabras independientes. Ésto se lo conoce como [Markov Assumption](https://es.wikipedia.org/wiki/Proceso_de_M%C3%A1rkov)\n",
    "\n",
    "Entonces teniendo en cuenta lo mencionado:\n",
    "\n",
    "`P(unTexto | c) = P(w1 | c) * P(w2 | c) * ... * P(wn | c)`\n",
    "\n",
    "Siendo\n",
    "\n",
    "`P(unaPalabra | c) = count(unaPalabra, c) / count(palabras, c)`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from repository.csv_tools import get_documents\n",
    "import random\n",
    "from util.count_vectorizer import MyCountVectorizer\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from models.naive_bayes_utils import *"
   ]
  },
  {
   "source": [
    "## Preparación del dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents('../data/dataset.csv')\n",
    "preprocessed_docs = [(document.lemmatized_string, document.topic) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, classes_train, text_test, classes_test = split_dataset(preprocessed_docs, 0.2)"
   ]
  },
  {
   "source": [
    "## Entrenamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = set(classes_train)\n",
    "frequencies = {}\n",
    "probabilities = {}\n",
    "features_by_class = {}\n",
    "\n",
    "def process(topic):\n",
    "    documents = get_documents_from_class(texts_train, classes_train, topic)\n",
    "\n",
    "    vectorizer           = MyCountVectorizer(preprocess = False)\n",
    "    term_document_matrix = vectorizer.fit_transform(documents)\n",
    "    word_list            = get_words(vectorizer)\n",
    "    count_list           = get_words_count(term_document_matrix)\n",
    "\n",
    "    __frequencies = get_frecuencies(word_list, count_list)\n",
    "    __probabilities = get_probabilities(word_list, count_list)\n",
    "    __features_by_class = get_features_count(count_list)\n",
    "   \n",
    "    return (__frequencies, __probabilities, __features_by_class, topic)\n",
    "    \n",
    "\n",
    "with Pool(10) as pool:\n",
    "    results = pool.map(process, classes)\n",
    "\n",
    "for result in results:\n",
    "    topic = result[3]\n",
    "    frequencies[topic] = result[0]\n",
    "    probabilities[topic] = result[1]\n",
    "    features_by_class[topic] = result[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total features: 4026\n"
     ]
    }
   ],
   "source": [
    "total_features = get_total_features(frequencies, classes)\n",
    "print('Total features: {}'.format(total_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class: Sistemas emergentes has a P = 0.11428571428571428\nClass: Economia de experiencia has a P = 0.20408163265306123\nClass: La sociedad de costo marginal cero has a P = 0.12244897959183673\nClass: Adopcion y difusion has a P = 0.1673469387755102\nClass: Nueva economia has a P = 0.024489795918367346\nClass: Marketing 4.0 has a P = 0.04897959183673469\nClass: La larga cola has a P = 0.16326530612244897\nClass: Wikinomics has a P = 0.08979591836734693\nClass: E-commerce has a P = 0.0326530612244898\nClass: Domotica has a P = 0.004081632653061225\nClass: Plataformas y modelos de negocio has a P = 0.012244897959183673\nClass: El dominio de la informacion has a P = 0.004081632653061225\nClass: Python has a P = 0.004081632653061225\nClass: Machine - Platform - Crowd has a P = 0.00816326530612245\n"
     ]
    }
   ],
   "source": [
    "class_probabilities = get_class_probabilities(classes_train)\n",
    "\n",
    "for topic in class_probabilities.keys():\n",
    "    print('Class: {} has a P = {}'.format(topic, class_probabilities[topic]))"
   ]
  },
  {
   "source": [
    "## Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_to_save = pd.Series(frequencies, name='Frequencies')\n",
    "classes_to_save = pd.Series(list(classes), name = 'Classes')\n",
    "features_by_class_to_save = pd.Series(features_by_class, name = 'Features by Class')\n",
    "class_probabilities_to_save = pd.Series(class_probabilities, name = 'Class Probabilities')\n",
    "\n",
    "frequencies_to_save.to_csv('../data/frequencies.nv')\n",
    "classes_to_save.to_csv('../data/classes.nv')\n",
    "features_by_class_to_save.to_csv('../data/features_by_class.nv')\n",
    "class_probabilities_to_save.to_csv('../data/class_probabilities.nv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For document #0: Predicted topic: E-commerce with P = -2556.6318297936887. Real topic: E-commerce\n",
      "For document #1: Predicted topic: Sistemas emergentes with P = -945.7805845026855. Real topic: Sistemas emergentes\n",
      "For document #2: Predicted topic: Economia de experiencia with P = -1679.586289126356. Real topic: Economia de experiencia\n",
      "For document #3: Predicted topic: Economia de experiencia with P = -2314.495551122855. Real topic: Economia de experiencia\n",
      "For document #4: Predicted topic: Wikinomics with P = -2582.983722643466. Real topic: Wikinomics\n",
      "For document #5: Predicted topic: Economia de experiencia with P = -1873.2049604607662. Real topic: Economia de experiencia\n",
      "For document #6: Predicted topic: Economia de experiencia with P = -2355.3265160669066. Real topic: Economia de experiencia\n",
      "For document #7: Predicted topic: La larga cola with P = -2053.2087088207068. Real topic: La larga cola\n",
      "For document #8: Predicted topic: La larga cola with P = -2822.4877297124663. Real topic: La larga cola\n",
      "For document #9: Predicted topic: Adopcion y difusion with P = -1455.0349256067711. Real topic: Adopcion y difusion\n",
      "For document #10: Predicted topic: Economia de experiencia with P = -1615.6638185761751. Real topic: Economia de experiencia\n",
      "For document #11: Predicted topic: Sistemas emergentes with P = -1090.3501094883857. Real topic: Sistemas emergentes\n",
      "For document #12: Predicted topic: Wikinomics with P = -1847.0100053685708. Real topic: Wikinomics\n",
      "For document #13: Predicted topic: Economia de experiencia with P = -2373.3177449108903. Real topic: Economia de experiencia\n",
      "For document #14: Predicted topic: Sistemas emergentes with P = -1208.377133312487. Real topic: Sistemas emergentes\n",
      "For document #15: Predicted topic: La sociedad de costo marginal cero with P = -1898.237880196763. Real topic: La sociedad de costo marginal cero\n",
      "For document #16: Predicted topic: Nueva economia with P = -1475.9630048205054. Real topic: Nueva economia\n",
      "For document #17: Predicted topic: Adopcion y difusion with P = -2105.721177597859. Real topic: Adopcion y difusion\n",
      "For document #18: Predicted topic: Economia de experiencia with P = -2654.472833751491. Real topic: Economia de experiencia\n",
      "For document #19: Predicted topic: La sociedad de costo marginal cero with P = -2692.875520858629. Real topic: La sociedad de costo marginal cero\n",
      "For document #20: Predicted topic: La larga cola with P = -2283.404803106915. Real topic: La larga cola\n",
      "For document #21: Predicted topic: La larga cola with P = -1864.684681794072. Real topic: La larga cola\n",
      "For document #22: Predicted topic: Sistemas emergentes with P = -1211.4596218577033. Real topic: Sistemas emergentes\n",
      "For document #23: Predicted topic: Sistemas emergentes with P = -1334.5517724403119. Real topic: Sistemas emergentes\n",
      "For document #24: Predicted topic: La sociedad de costo marginal cero with P = -1598.0426297506856. Real topic: La sociedad de costo marginal cero\n",
      "For document #25: Predicted topic: Wikinomics with P = -1870.2572224979046. Real topic: Wikinomics\n",
      "For document #26: Predicted topic: Adopcion y difusion with P = -1879.3251864174285. Real topic: Adopcion y difusion\n",
      "For document #27: Predicted topic: La larga cola with P = -2283.404803106915. Real topic: La larga cola\n",
      "For document #28: Predicted topic: Economia de experiencia with P = -3125.9507743825116. Real topic: Economia de experiencia\n",
      "For document #29: Predicted topic: Economia de experiencia with P = -1668.1408229977617. Real topic: Economia de experiencia\n",
      "For document #30: Predicted topic: Economia de experiencia with P = -1714.7867541978276. Real topic: Economia de experiencia\n",
      "For document #31: Predicted topic: Sistemas emergentes with P = -2540.683651956285. Real topic: Sistemas emergentes\n",
      "For document #32: Predicted topic: La sociedad de costo marginal cero with P = -2417.8522735412644. Real topic: La sociedad de costo marginal cero\n",
      "For document #33: Predicted topic: La larga cola with P = -2278.406967648403. Real topic: La larga cola\n",
      "For document #34: Predicted topic: Marketing 4.0 with P = -2297.43868364383. Real topic: Marketing 4.0\n",
      "For document #35: Predicted topic: La larga cola with P = -1268.371765573745. Real topic: La larga cola\n",
      "For document #36: Predicted topic: Adopcion y difusion with P = -1675.3870160578213. Real topic: Adopcion y difusion\n",
      "For document #37: Predicted topic: La larga cola with P = -1764.5496596425774. Real topic: La larga cola\n",
      "For document #38: Predicted topic: La larga cola with P = -2478.2644034569666. Real topic: La larga cola\n",
      "For document #39: Predicted topic: Adopcion y difusion with P = -2164.574659360463. Real topic: Adopcion y difusion\n",
      "For document #40: Predicted topic: La sociedad de costo marginal cero with P = -1598.0426297506856. Real topic: La sociedad de costo marginal cero\n",
      "For document #41: Predicted topic: Economia de experiencia with P = -3125.9507743825116. Real topic: Economia de experiencia\n",
      "For document #42: Predicted topic: Adopcion y difusion with P = -3037.392743869574. Real topic: Adopcion y difusion\n",
      "For document #43: Predicted topic: La larga cola with P = -2257.044836893634. Real topic: La larga cola\n",
      "For document #44: Predicted topic: Marketing 4.0 with P = -2934.719999574087. Real topic: Marketing 4.0\n",
      "For document #45: Predicted topic: Machine - Platform - Crowd with P = -2273.4099522906076. Real topic: Machine - Platform - Crowd\n",
      "For document #46: Predicted topic: Sistemas emergentes with P = -1169.2734373110745. Real topic: Sistemas emergentes\n",
      "For document #47: Predicted topic: La larga cola with P = -2465.964894157111. Real topic: La larga cola\n",
      "For document #48: Predicted topic: Adopcion y difusion with P = -2708.648508535094. Real topic: Adopcion y difusion\n",
      "For document #49: Predicted topic: La sociedad de costo marginal cero with P = -1856.5275882688027. Real topic: La sociedad de costo marginal cero\n",
      "For document #50: Predicted topic: Economia de experiencia with P = -2079.5962310580094. Real topic: Economia de experiencia\n",
      "For document #51: Predicted topic: La sociedad de costo marginal cero with P = -1700.1690902226546. Real topic: La sociedad de costo marginal cero\n",
      "For document #52: Predicted topic: Adopcion y difusion with P = -1921.2245527197588. Real topic: Adopcion y difusion\n",
      "For document #53: Predicted topic: La larga cola with P = -1971.6224541643842. Real topic: La larga cola\n",
      "For document #54: Predicted topic: Wikinomics with P = -3886.4072482182614. Real topic: Wikinomics\n",
      "For document #55: Predicted topic: Economia de experiencia with P = -1556.6851800072884. Real topic: Economia de experiencia\n",
      "For document #56: Predicted topic: La larga cola with P = -2751.269695700497. Real topic: La larga cola\n",
      "For document #57: Predicted topic: E-commerce with P = -1630.6097229538714. Real topic: E-commerce\n",
      "For document #58: Predicted topic: Wikinomics with P = -2863.5119000068757. Real topic: Wikinomics\n",
      "For document #59: Predicted topic: La larga cola with P = -2643.5700646860787. Real topic: La larga cola\n",
      "For document #60: Predicted topic: La sociedad de costo marginal cero with P = -2692.875520858629. Real topic: La sociedad de costo marginal cero\n",
      "For document #61: Predicted topic: Sistemas emergentes with P = -606.5508164985922. Real topic: Sistemas emergentes\n"
     ]
    }
   ],
   "source": [
    "for ix, document in enumerate(text_test[:]):\n",
    "\n",
    "    predicted_probabilities = {}\n",
    "\n",
    "    for topic in classes:\n",
    "        words_probability = get_words_probabilities(document, topic, frequencies, total_features, features_by_class)\n",
    "        P = math.log(class_probabilities[topic], 2)\n",
    "        for key in words_probability.keys():\n",
    "            p = words_probability[key]\n",
    "            P += math.log(p, 2)\n",
    "        predicted_probabilities[topic] = P\n",
    "    \n",
    "    topic_predicted, probability_predicted = get_topic_predicted(predicted_probabilities)\n",
    "    print('For document #{}: Predicted topic: {} with P = {}. Real topic: {}'.format(ix, topic_predicted, probability_predicted, classes_test[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}