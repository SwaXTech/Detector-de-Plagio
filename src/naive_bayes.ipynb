{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpconda58a66029c51549b7b2d39520295f4ea7",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## Modelo de clasificación de textos de manera supervisada\n",
    "\n",
    "- [Documentación utilizada](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b#:~:text=The%20Naive%20Bayes%20classifier%20is,time%20and%20less%20training%20data)\n",
    "\n",
    "- [Referencia](https://www.campusvirtual.frba.utn.edu.ar/especialidad/pluginfile.php/300766/mod_resource/content/1/NLP%20-%20UTN%20-%20Clase%203.pdf)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Preparación del dataset\n",
    "\n",
    "- Obtención del dataset de un `CSV`\n",
    "- Ignoramos las columnas innecesarias\n",
    "- Limpieza de datos\n",
    "- Separación de dataset en Train/Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Teorema de Bayes\n",
    "\n",
    "![](https://miro.medium.com/max/358/1*8vBP06EtIIf-420o_q1u6g.png)\n",
    "\n",
    "\n",
    "Se debe calcular qué tópico tiene mayor probabilidad para una texto determinado\n",
    "\n",
    "¿`P(c1 | unTexto)` es mayor que `P(c2 | unTexto)`?\n",
    "\n",
    "Según el Teorema de Bayes, esto se puede calcular de la siguiente manera:\n",
    "\n",
    "`P(c | unTexto) = (P(unTexto | c) * P(c)) / P(unTexto)`\n",
    "\n",
    "Como para ambas clases el denominador es el mismo, podemos ignorarlo y nos queda:\n",
    "\n",
    "`P(c | unTexto) = P(unTexto | c) * P(c)`\n",
    "\n",
    "Finalmente\n",
    "\n",
    "`P(c) = count(textos, c) / count(textos, dataset)` \n",
    "\n",
    "`P(unTexto) = count(unTexto, c) / count(textos, c)`\n",
    "\n",
    "Dado que los textos a evaluar no necesariamente aparecen en el dataset, y por consiguiente su probabilidad es cero. Entonces se asumen todas las palabras independientes. Ésto se lo conoce como [Markov Assumption](https://es.wikipedia.org/wiki/Proceso_de_M%C3%A1rkov)\n",
    "\n",
    "Entonces teniendo en cuenta lo mencionado:\n",
    "\n",
    "`P(unTexto | c) = P(w1 | c) * P(w2 | c) * ... * P(wn | c)`\n",
    "\n",
    "Siendo\n",
    "\n",
    "`P(unaPalabra | c) = count(unaPalabra, c) / count(palabras, c)`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from repository.csv_tools import get_documents\n",
    "import random\n",
    "from util.count_vectorizer import MyCountVectorizer\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from models.naive_bayes_utils import *"
   ]
  },
  {
   "source": [
    "## Preparación del dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents('../data/dataset.csv')\n",
    "preprocessed_docs = [(document.lemmatized_string, document.topic) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, classes_train, text_test, classes_test = split_dataset(preprocessed_docs, 0.2)"
   ]
  },
  {
   "source": [
    "## Entrenamiento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = set(classes_train)\n",
    "frequencies = {}\n",
    "probabilities = {}\n",
    "features_by_class = {}\n",
    "\n",
    "def process(topic):\n",
    "    documents = get_documents_from_class(texts_train, classes_train, topic)\n",
    "\n",
    "    vectorizer           = MyCountVectorizer(preprocess = False)\n",
    "    term_document_matrix = vectorizer.fit_transform(documents)\n",
    "    word_list            = get_words(vectorizer)\n",
    "    count_list           = get_words_count(term_document_matrix)\n",
    "\n",
    "    __frequencies = get_frecuencies(word_list, count_list)\n",
    "    __probabilities = get_probabilities(word_list, count_list)\n",
    "    __features_by_class = get_features_count(count_list)\n",
    "   \n",
    "    return (__frequencies, __probabilities, __features_by_class, topic)\n",
    "    \n",
    "\n",
    "with Pool(10) as pool:\n",
    "    results = pool.map(process, classes)\n",
    "\n",
    "for result in results:\n",
    "    topic = result[3]\n",
    "    frequencies[topic] = result[0]\n",
    "    probabilities[topic] = result[1]\n",
    "    features_by_class[topic] = result[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total features: 4250\n"
     ]
    }
   ],
   "source": [
    "total_features = get_total_features(frequencies, classes)\n",
    "print('Total features: {}'.format(total_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class: Economia de experiencia has a P = 0.18775510204081633\nClass: La larga cola has a P = 0.17551020408163265\nClass: La sociedad de costo marginal cero has a P = 0.12244897959183673\nClass: Sistemas emergentes has a P = 0.11836734693877551\nClass: Wikinomics has a P = 0.10612244897959183\nClass: Marketing 4.0 has a P = 0.04081632653061224\nClass: Machine - Platform - Crowd has a P = 0.0163265306122449\nClass: El dominio de la informacion has a P = 0.00816326530612245\nClass: Nueva economia has a P = 0.024489795918367346\nClass: Realidad virtual has a P = 0.004081632653061225\nClass: E-commerce has a P = 0.02040816326530612\nClass: Adopcion y difusion has a P = 0.15918367346938775\nClass: Plataformas y modelos de negocio has a P = 0.012244897959183673\nClass: Python has a P = 0.004081632653061225\n"
     ]
    }
   ],
   "source": [
    "class_probabilities = get_class_probabilities(classes_train)\n",
    "\n",
    "for topic in class_probabilities.keys():\n",
    "    print('Class: {} has a P = {}'.format(topic, class_probabilities[topic]))"
   ]
  },
  {
   "source": [
    "## Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.naive_bayes_utils import NaiveBayes\n",
    "classifier = NaiveBayes()\n",
    "classifier.init(frequencies, classes, features_by_class, class_probabilities)\n",
    "classifier.save_model(path = '../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For document #0: Predicted topic: Nueva economia with P = -2122.121033677826. Real topic: Domotica\n",
      "For document #1: Predicted topic: Adopcion y difusion with P = -2589.8611729222152. Real topic: Adopcion y difusion\n",
      "For document #2: Predicted topic: Economia de experiencia with P = -1974.9023349695935. Real topic: Economia de experiencia\n",
      "For document #3: Predicted topic: Economia de experiencia with P = -1883.3109999879853. Real topic: Economia de experiencia\n",
      "For document #4: Predicted topic: Economia de experiencia with P = -1141.0396286677815. Real topic: Economia de experiencia\n",
      "For document #5: Predicted topic: Adopcion y difusion with P = -1547.6873334097795. Real topic: Adopcion y difusion\n",
      "For document #6: Predicted topic: Economia de experiencia with P = -1377.634466855529. Real topic: Economia de experiencia\n",
      "For document #7: Predicted topic: Economia de experiencia with P = -1738.1873342733445. Real topic: Economia de experiencia\n",
      "For document #8: Predicted topic: Nueva economia with P = -1538.5358692210402. Real topic: Nueva economia\n",
      "For document #9: Predicted topic: Adopcion y difusion with P = -3059.4753339271724. Real topic: Adopcion y difusion\n",
      "For document #10: Predicted topic: Economia de experiencia with P = -2045.029522672634. Real topic: Economia de experiencia\n",
      "For document #11: Predicted topic: Marketing 4.0 with P = -2247.7399703975866. Real topic: Marketing 4.0\n",
      "For document #12: Predicted topic: La larga cola with P = -2443.3781243181397. Real topic: La larga cola\n",
      "For document #13: Predicted topic: La sociedad de costo marginal cero with P = -1856.9134079857113. Real topic: La sociedad de costo marginal cero\n",
      "For document #14: Predicted topic: Adopcion y difusion with P = -2475.54806285357. Real topic: Adopcion y difusion\n",
      "For document #15: Predicted topic: La sociedad de costo marginal cero with P = -1700.1809279049603. Real topic: La sociedad de costo marginal cero\n",
      "For document #16: Predicted topic: Economia de experiencia with P = -2035.150912307281. Real topic: Economia de experiencia\n",
      "For document #17: Predicted topic: La larga cola with P = -2628.064689441396. Real topic: La larga cola\n",
      "For document #18: Predicted topic: La sociedad de costo marginal cero with P = -1651.6152848219742. Real topic: La sociedad de costo marginal cero\n",
      "For document #19: Predicted topic: La larga cola with P = -2221.4574298063435. Real topic: La larga cola\n",
      "For document #20: Predicted topic: La larga cola with P = -3133.4236145943846. Real topic: La larga cola\n",
      "For document #21: Predicted topic: Adopcion y difusion with P = -2444.9294229538796. Real topic: Adopcion y difusion\n",
      "For document #22: Predicted topic: Sistemas emergentes with P = -1204.971414377952. Real topic: Sistemas emergentes\n",
      "For document #23: Predicted topic: Economia de experiencia with P = -2457.0197221370427. Real topic: Economia de experiencia\n",
      "For document #24: Predicted topic: El dominio de la informacion with P = -5690.573090210943. Real topic: El dominio de la informacion\n",
      "For document #25: Predicted topic: E-commerce with P = -1819.1956392384875. Real topic: E-commerce\n",
      "For document #26: Predicted topic: Economia de experiencia with P = -1560.8237876595808. Real topic: Economia de experiencia\n",
      "For document #27: Predicted topic: E-commerce with P = -1847.3010486036835. Real topic: E-commerce\n",
      "For document #28: Predicted topic: La larga cola with P = -2469.0810855454383. Real topic: La larga cola\n",
      "For document #29: Predicted topic: Marketing 4.0 with P = -2934.9422546214296. Real topic: Marketing 4.0\n",
      "For document #30: Predicted topic: Economia de experiencia with P = -2670.026343222114. Real topic: Economia de experiencia\n",
      "For document #31: Predicted topic: Economia de experiencia with P = -1668.3284345645477. Real topic: Economia de experiencia\n",
      "For document #32: Predicted topic: Adopcion y difusion with P = -2263.0561394946994. Real topic: Adopcion y difusion\n",
      "For document #33: Predicted topic: E-commerce with P = -1038.7447504322388. Real topic: E-commerce\n",
      "For document #34: Predicted topic: Wikinomics with P = -2854.548969750386. Real topic: Wikinomics\n",
      "For document #35: Predicted topic: Adopcion y difusion with P = -1547.6873334097795. Real topic: Adopcion y difusion\n",
      "For document #36: Predicted topic: Adopcion y difusion with P = -2129.4247823592705. Real topic: Adopcion y difusion\n",
      "For document #37: Predicted topic: Marketing 4.0 with P = -3076.7432234463427. Real topic: Marketing 4.0\n",
      "For document #38: Predicted topic: E-commerce with P = -1455.138163444685. Real topic: E-commerce\n",
      "For document #39: Predicted topic: Sistemas emergentes with P = -1057.4562227848662. Real topic: Sistemas emergentes\n",
      "For document #40: Predicted topic: La sociedad de costo marginal cero with P = -2053.475515038008. Real topic: La sociedad de costo marginal cero\n",
      "For document #41: Predicted topic: E-commerce with P = -1337.3767019343202. Real topic: E-commerce\n",
      "For document #42: Predicted topic: Economia de experiencia with P = -2389.266313723884. Real topic: Economia de experiencia\n",
      "For document #43: Predicted topic: Economia de experiencia with P = -1668.5278375756623. Real topic: Economia de experiencia\n",
      "For document #44: Predicted topic: La sociedad de costo marginal cero with P = -1728.5041269671099. Real topic: La sociedad de costo marginal cero\n",
      "For document #45: Predicted topic: Adopcion y difusion with P = -2713.942466123547. Real topic: Adopcion y difusion\n",
      "For document #46: Predicted topic: Wikinomics with P = -2580.593180994339. Real topic: Wikinomics\n",
      "For document #47: Predicted topic: La sociedad de costo marginal cero with P = -2389.094229805632. Real topic: La sociedad de costo marginal cero\n",
      "For document #48: Predicted topic: La larga cola with P = -2246.1504174071056. Real topic: La larga cola\n",
      "For document #49: Predicted topic: Adopcion y difusion with P = -1884.6392465183883. Real topic: Adopcion y difusion\n",
      "For document #50: Predicted topic: Marketing 4.0 with P = -3441.2785268682646. Real topic: Marketing 4.0\n",
      "For document #51: Predicted topic: La larga cola with P = -1975.0957491566494. Real topic: La larga cola\n",
      "For document #52: Predicted topic: Economia de experiencia with P = -1141.0396286677815. Real topic: Economia de experiencia\n",
      "For document #53: Predicted topic: Adopcion y difusion with P = -2833.426792271043. Real topic: Adopcion y difusion\n",
      "For document #54: Predicted topic: Adopcion y difusion with P = -1667.7101867999406. Real topic: Adopcion y difusion\n",
      "For document #55: Predicted topic: Sistemas emergentes with P = -603.8432349185193. Real topic: Sistemas emergentes\n",
      "For document #56: Predicted topic: Marketing 4.0 with P = -2604.2042672456314. Real topic: Marketing 4.0\n",
      "For document #57: Predicted topic: Economia de experiencia with P = -3083.2670575301504. Real topic: Economia de experiencia\n",
      "For document #58: Predicted topic: Adopcion y difusion with P = -3056.821018809839. Real topic: Adopcion y difusion\n",
      "For document #59: Predicted topic: Economia de experiencia with P = -1377.634466855529. Real topic: Economia de experiencia\n",
      "For document #60: Predicted topic: La larga cola with P = -1729.4441215294569. Real topic: La larga cola\n"
     ]
    }
   ],
   "source": [
    "successfuly = 0\n",
    "failed = 0 \n",
    "total = len(text_test)\n",
    "\n",
    "for ix, document in enumerate(text_test[:]):\n",
    "    topic_predicted, probability_predicted = classifier.topic(document)\n",
    "    if topic_predicted == classes_test[ix]:\n",
    "        successfuly += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "    print('For document #{}: Predicted topic: {} with P = {}. Real topic: {}'.format(ix, topic_predicted, probability_predicted, classes_test[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "El modelo acertó el 98.36065573770492% de las veces\nEl modelo falló el 1.639344262295082% de las veces\n"
     ]
    }
   ],
   "source": [
    "fiability = {\n",
    "\n",
    "    'accuracy': (successfuly*100)/total,\n",
    "    'failed': (failed*100)/total\n",
    "}\n",
    "\n",
    "print('El modelo acertó el {}% de las veces'.format(fiability['accuracy']))\n",
    "print('El modelo falló el {}% de las veces'.format(fiability['failed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=fiability).to_csv('../data/accuracy.nv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}