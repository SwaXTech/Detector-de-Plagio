{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnlpconda58a66029c51549b7b2d39520295f4ea7",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web Scrapper\n",
    "\n",
    "- Obtener resultados de google\n",
    "- Obtener los pÃ¡rrafos de cada resultado\n",
    "- Preprocesar y guardar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.scrapper import *\n",
    "from models.lda_utils import get_keywords\n",
    "import re\n",
    "is_well_formed_link = re.compile(r'^https?://.+/.+$')\n",
    "\n",
    "def is_useful(string):\n",
    "    return string != '\\n'\n",
    "\n",
    "keywords = get_keywords()\n",
    "data = []\n",
    "for keyword in keywords:\n",
    "    try:\n",
    "        results = scrape_google(keyword, 3, \"es\")\n",
    "        for result in results:\n",
    "            data.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "links = [result['link'] for result in data if is_well_formed_link.match(result['link'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['estrategia precio red coste control caso usuario copia positivo preguntar',\n",
       " 'experiencia cliente masivo valor sacrificio oferta individuo necesidad campo tema',\n",
       " 'cliente experiencia valor masivo negocio necesidad diferencia ciberespacio misma precio',\n",
       " 'cliente marca social comunidad conectividad horizontal mundo precio red concepto',\n",
       " 'emergente conducta organismo comportamiento complejo agente desarrollar superior regla complejas',\n",
       " 'plataforma conocimiento red fuente dato colaborativa valor com modelo humano',\n",
       " 'adoptar innovador individuo consumidor modelo gente pc grupo rol coeficiente',\n",
       " 'rifkin industrial infraestructura marginal actual ley decir sociedad factura capitalista',\n",
       " 'coste tarea global compartir concepto favorecer ley coase emergencia capacidad',\n",
       " 'largo cola ofrecer venta regla cliente demanda nicho oferta minorista']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from models.lda_utils import get_keywords\n",
    "get_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://br.escueladenegociosydireccion.com/business/marketing-ventas/estrategias-de-precios-en-un-mercado-competitivo/',\n",
       " 'https://es.semrush.com/blog/estrategia-de-precios/',\n",
       " 'http://diposit.ub.edu/dspace/bitstream/2445/66261/1/TFM_MOI_Pedrero-Yolanda-jun2015.pdf',\n",
       " 'http://tdx.cat/bitstream/handle/10803/396345/TD_2016_TenaMonferrer.pdf?sequence=1&isAllowed=y',\n",
       " 'https://www.tesisenred.net/bitstream/handle/10803/146251/David_Rodriguez_Rabad%C3%A1n%20Benito.pdf?sequence=1&isAllowed=y',\n",
       " 'https://www.tesisenred.net/bitstream/handle/10803/385276/tesdoc_a2016_roman_david_analisis_promociones.pdf?sequence=1&isAllowed=y',\n",
       " 'https://rockcontent.com/es/blog/marketing-digital/',\n",
       " 'https://core.ac.uk/download/pdf/44310136.pdf',\n",
       " 'https://e-archivo.uc3m.es/bitstream/handle/10016/22498/rosario_rivera_tesis.pdf',\n",
       " 'https://www.vocesenelfenix.com/content/la-%E2%80%9Crevoluci%C3%B3n%E2%80%9D-de-las-redes-sociales-sociedad-educaci%C3%B3n-y-nueva-profesi%C3%B3n',\n",
       " 'https://dialnet.unirioja.es/descarga/libro/511130.pdf',\n",
       " 'https://es.wikipedia.org/wiki/Red_social',\n",
       " 'https://www.ucasal.edu.ar/htm/ingenieria/cuadernos/archivos/3-p46-Venturini.pdf',\n",
       " 'https://journals.openedition.org/polis/536',\n",
       " 'https://es.wikipedia.org/wiki/Emergencia_(filosof%C3%ADa)',\n",
       " 'https://www.tdx.cat/bitstream/handle/10803/59037/tmge1de1.pdf?sequence=1&isAllowed=y',\n",
       " 'https://dialnet.unirioja.es/servlet/tesis?codigo=26326&orden=388901&info=link',\n",
       " 'https://capaball.com/blog/16-plataformas-educativas-cual-elegir/',\n",
       " 'https://www.bbvaresearch.com/wp-content/uploads/2015/11/15-28_WP-Ec_Digital_e.pdf',\n",
       " 'https://www.scielo.br/scielo.php?pid=S1679-39512011000100011&script=sci_arttext',\n",
       " 'https://dialnet.unirioja.es/descarga/articulo/116404.pdf',\n",
       " 'http://transicionsocioeconomica.blogspot.com/2015/10/la-sociedad-de-coste-marginal-cero.html',\n",
       " 'http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S0188-25032016000100161',\n",
       " 'https://www.popularlibros.com/archivos/9788449330513.pdf',\n",
       " 'https://www.elblogsalmon.com/conceptos-de-economia/de-los-costes-de-transaccion-a-la-ley-de-coase',\n",
       " 'https://www.exapuni.com/carreras/apunteHash/4acb2035ee286987d5c2b7098d4b2363',\n",
       " 'https://es.wikipedia.org/wiki/Teorema_de_Coase',\n",
       " 'https://javiermegias.com/blog/2013/12/modelos-de-negocio-long-tail-larga-cola/',\n",
       " 'https://es.qaz.wiki/wiki/Long_tail']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        content = urllib.request.urlopen(link)\n",
    "        read_content = content.read()\n",
    "        soup = BeautifulSoup(read_content,'html.parser')\n",
    "        pAll = soup.find_all('p')\n",
    "        paragraphs[link]= list(filter(is_useful, [p.text for p in pAll]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_useful(p):\n",
    "    return len(p) > 3\n",
    "\n",
    "for key in paragraphs.keys():\n",
    "    paragraphs[key] = list(filter(is_useful, paragraphs[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document import Document\n",
    "preprocess_list = ['lemmatized_string', 'sentences', 'preprocessed_sentences', 'paragraphs', 'preprocessed_paragraphs']\n",
    "documents = []\n",
    "\n",
    "for key in paragraphs.keys():\n",
    "    p = paragraphs[key]\n",
    "    if len(p) != 0:\n",
    "        doc = Document()\n",
    "        doc.from_paragraphs(paragraphs = paragraphs[key], preprocess_list=preprocess_list)\n",
    "        doc.title = key\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(document):\n",
    "    return [document.title, document.title, document.string, document.word_count(), document.type_count(), document.sentences,\\\n",
    "                       document.lemmatized_string, document.stemmed_string, document.simple_preprocessed_string, document.topic, \\\n",
    "                       document.named_entities, document.bigrams, document.trigrams, document.lemmatized_bigrams, \\\n",
    "                       document.lemmatized_trigrams, document.stemmed_bigrams, document.stemmed_trigrams, \\\n",
    "                       document.simple_preprocessed_bigrams, document.simple_preprocessed_trigrams, document.preprocessed_sentences,\n",
    "                       document.paragraphs, document.preprocessed_paragraphs, document.urls]\n",
    "\n",
    "scrapped = [process_file(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe_scrapped = pd.DataFrame(data = scrapped, columns=['original_path', 'document_title', 'string', 'word_count', 'type_count', 'sentences','lemmatized_text', 'stemmed_text', 'simple_preprocessed', 'topic', 'named_entities', 'tokens_bigrams', 'tokens_trigrams', 'lemmatized_bigrams', 'lemmatized_trigrams', 'stemmed_bigrams', 'stemmed_trigrams', 'simple_preprocessed_bigrams', 'simple_preprocessed_trigrams', 'preprocessed_sentences', 'paragraphs', 'preprocessed_paragraphs', 'urls'])\n",
    "dataframe_scrapped.to_csv('../data/scrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}